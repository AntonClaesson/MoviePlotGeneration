{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c7ffc5",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "\n",
    "**Fix class imbalance** \n",
    "  * using NLP data augmentation https://neptune.ai/blog/data-augmentation-nlp So for examples containing rare genres and no common genres we can oversample with augmentation techniques. Problem: We have multi-label problem (many genres possible). To decide how to oversample we can have a \"repeat ceiling\". Better way would be to utlize \n",
    "  https://medium.com/thecyphy/handling-data-imbalance-in-multi-label-classification-mlsmote-531155416b87\n",
    "  https://link.springer.com/chapter/10.1007/978-3-642-40846-5_16 to decide which examples to oversample.\n",
    "  \n",
    "  \n",
    "**Fine-tune using distilgpt2** \n",
    "  * GPT2 is too large for our GPU so we use distilled version https://huggingface.co/distilgpt2\n",
    "  * For best performance: Make LM dataset using plots only and finetune the model a bit on this. (Large text document with each plot after the other. See example notebook from hugging face)\n",
    "  * Once the model outputs plot-like text, we want to train using the labeled dataset with genres and title.\n",
    "  \n",
    "** to start **\n",
    "Since we won't have time to do everything probably, let's start with the current dataset and just try to see what happens if we simply finetune w/o any augmentation and no pre-training on plot text.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd26678",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook implements a pre-trained GPT language model to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e454366d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (4.11.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (1.13.2)\n",
      "Requirement already satisfied: git-lfs in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (1.6)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: filelock in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages\\sacremoses-0.0.43-py3.8.egg (from transformers) (0.0.43)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: dill in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from datasets) (2021.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipywidgets) (7.27.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.4.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pygments in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (228)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: click in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\anton\\anaconda3\\envs\\storygen\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets git-lfs ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914a8f38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\Anton\\Anaconda3\\envs\\storygen:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "abseil-cpp                20210324.2           h0e60522_0    conda-forge\n",
      "aiohttp                   3.7.4.post0      py38h294d835_0    conda-forge\n",
      "argon2-cffi               21.1.0           py38h294d835_0    conda-forge\n",
      "arrow-cpp                 5.0.0           py38h9929e98_8_cpu    conda-forge\n",
      "async-timeout             3.0.1                   py_1000    conda-forge\n",
      "async_generator           1.10                       py_0    conda-forge\n",
      "attrs                     21.2.0             pyhd8ed1ab_0    conda-forge\n",
      "aws-c-cal                 0.5.11               he19cf47_0    conda-forge\n",
      "aws-c-common              0.6.2                h8ffe710_0    conda-forge\n",
      "aws-c-event-stream        0.2.7               h70e1b0c_13    conda-forge\n",
      "aws-c-io                  0.10.5               h2fe331c_0    conda-forge\n",
      "aws-checksums             0.1.11               h1e232aa_7    conda-forge\n",
      "aws-sdk-cpp               1.8.186              hb0612c5_3    conda-forge\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \n",
      "blas                      2.111                       mkl    conda-forge\n",
      "blas-devel                3.9.0              11_win64_mkl    conda-forge\n",
      "bleach                    4.1.0              pyhd8ed1ab_0    conda-forge\n",
      "boto3                     1.18.21            pyhd3eb1b0_0  \n",
      "botocore                  1.21.41            pyhd3eb1b0_1  \n",
      "brotlipy                  0.7.0           py38h294d835_1001    conda-forge\n",
      "bzip2                     1.0.8                h8ffe710_4    conda-forge\n",
      "c-ares                    1.17.2               h8ffe710_0    conda-forge\n",
      "ca-certificates           2021.10.8            h5b45459_0    conda-forge\n",
      "certifi                   2021.10.8        py38haa244fe_0    conda-forge\n",
      "cffi                      1.14.6           py38hd8c33c5_1    conda-forge\n",
      "chardet                   4.0.0            py38haa244fe_1    conda-forge\n",
      "click                     8.0.1              pyhd3eb1b0_0  \n",
      "colorama                  0.4.4              pyhd3eb1b0_0  \n",
      "cryptography              35.0.0           py38hd7da0ea_0    conda-forge\n",
      "cudatoolkit               11.1.1               heb2d755_9    conda-forge\n",
      "cycler                    0.10.0                     py_2    conda-forge\n",
      "dataclasses               0.8                pyhc8e2a94_3    conda-forge\n",
      "datasets                  1.13.2                     py_0    huggingface\n",
      "debugpy                   1.4.1            py38hd77b12b_0  \n",
      "decorator                 5.1.0              pyhd3eb1b0_0  \n",
      "defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\n",
      "dill                      0.3.4              pyhd8ed1ab_0    conda-forge\n",
      "entrypoints               0.3                      py38_0  \n",
      "filelock                  3.3.0              pyhd8ed1ab_0    conda-forge\n",
      "freetype                  2.10.4               h546665d_1    conda-forge\n",
      "fsspec                    2021.10.0          pyhd8ed1ab_0    conda-forge\n",
      "gflags                    2.2.2             ha925a31_1004    conda-forge\n",
      "git-lfs                   1.6                      pypi_0    pypi\n",
      "glog                      0.5.0                h4797de2_0    conda-forge\n",
      "grpc-cpp                  1.40.0               h2431d41_2    conda-forge\n",
      "huggingface-hub           0.0.19                   pypi_0    pypi\n",
      "huggingface_hub           0.0.17                     py_0    huggingface\n",
      "icu                       68.1                 h0e60522_0    conda-forge\n",
      "idna                      2.10               pyh9f0ad1d_0    conda-forge\n",
      "importlib-metadata        4.8.1            py38haa244fe_0    conda-forge\n",
      "importlib_metadata        4.8.1                hd8ed1ab_0    conda-forge\n",
      "intel-openmp              2021.4.0          h57928b3_3556    conda-forge\n",
      "ipykernel                 6.4.1            py38haa95532_1  \n",
      "ipython                   7.27.0           py38hd4e2768_0  \n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \n",
      "ipywidgets                7.6.5              pyhd8ed1ab_0    conda-forge\n",
      "jbig                      2.1               h8d14728_2003    conda-forge\n",
      "jedi                      0.18.0           py38haa95532_1  \n",
      "jinja2                    3.0.2              pyhd8ed1ab_0    conda-forge\n",
      "jmespath                  0.10.0             pyhd3eb1b0_0  \n",
      "joblib                    1.0.1              pyhd3eb1b0_0  \n",
      "jpeg                      9d                   h8ffe710_0    conda-forge\n",
      "jsonschema                4.1.0              pyhd8ed1ab_0    conda-forge\n",
      "jupyter_client            7.0.1              pyhd3eb1b0_0  \n",
      "jupyter_core              4.8.1            py38haa95532_0  \n",
      "jupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\n",
      "jupyterlab_widgets        1.0.2              pyhd8ed1ab_0    conda-forge\n",
      "kiwisolver                1.3.2            py38hbd9d945_0    conda-forge\n",
      "krb5                      1.19.2               hbae68bd_2    conda-forge\n",
      "lcms2                     2.12                 h2a16943_0    conda-forge\n",
      "lerc                      3.0                  h0e60522_0    conda-forge\n",
      "libblas                   3.9.0              11_win64_mkl    conda-forge\n",
      "libbrotlicommon           1.0.9                h8ffe710_5    conda-forge\n",
      "libbrotlidec              1.0.9                h8ffe710_5    conda-forge\n",
      "libbrotlienc              1.0.9                h8ffe710_5    conda-forge\n",
      "libcblas                  3.9.0              11_win64_mkl    conda-forge\n",
      "libclang                  11.1.0          default_h5c34c98_1    conda-forge\n",
      "libcurl                   7.79.1               h789b8ee_1    conda-forge\n",
      "libdeflate                1.8                  h8ffe710_0    conda-forge\n",
      "liblapack                 3.9.0              11_win64_mkl    conda-forge\n",
      "liblapacke                3.9.0              11_win64_mkl    conda-forge\n",
      "libpng                    1.6.37               h1d00b33_2    conda-forge\n",
      "libprotobuf               3.18.1               h7755175_0    conda-forge\n",
      "libssh2                   1.10.0               h680486a_2    conda-forge\n",
      "libthrift                 0.15.0               h636ae23_1    conda-forge\n",
      "libtiff                   4.3.0                hd413186_2    conda-forge\n",
      "libutf8proc               2.6.1                hcb41399_0    conda-forge\n",
      "libuv                     1.42.0               h8ffe710_0    conda-forge\n",
      "libzlib                   1.2.11            h8ffe710_1013    conda-forge\n",
      "lz4-c                     1.9.3                h8ffe710_1    conda-forge\n",
      "m2w64-gcc-libgfortran     5.3.0                         6    conda-forge\n",
      "m2w64-gcc-libs            5.3.0                         7    conda-forge\n",
      "m2w64-gcc-libs-core       5.3.0                         7    conda-forge\n",
      "m2w64-gmp                 6.1.0                         2    conda-forge\n",
      "m2w64-libwinpthread-git   5.0.0.4634.697f757               2    conda-forge\n",
      "markupsafe                2.0.1            py38h294d835_0    conda-forge\n",
      "matplotlib                3.4.3            py38haa244fe_1    conda-forge\n",
      "matplotlib-base           3.4.3            py38h1f000d6_1    conda-forge\n",
      "matplotlib-inline         0.1.2              pyhd3eb1b0_2  \n",
      "mistune                   0.8.4           py38h294d835_1004    conda-forge\n",
      "mkl                       2021.3.0           hb70f87d_564    conda-forge\n",
      "mkl-devel                 2021.3.0           h57928b3_565    conda-forge\n",
      "mkl-include               2021.3.0           hb70f87d_564    conda-forge\n",
      "msys2-conda-epoch         20160418                      1    conda-forge\n",
      "multidict                 5.2.0            py38h294d835_0    conda-forge\n",
      "multiprocess              0.70.12.2        py38h294d835_0    conda-forge\n",
      "nbclient                  0.5.4              pyhd8ed1ab_0    conda-forge\n",
      "nbconvert                 6.2.0            py38haa244fe_0    conda-forge\n",
      "nbformat                  5.1.3              pyhd8ed1ab_0    conda-forge\n",
      "nest-asyncio              1.5.1              pyhd3eb1b0_0  \n",
      "ninja                     1.10.2               h2d74725_1    conda-forge\n",
      "notebook                  6.4.4              pyha770c72_0    conda-forge\n",
      "numpy                     1.21.2           py38h089cfbf_0    conda-forge\n",
      "olefile                   0.46               pyh9f0ad1d_1    conda-forge\n",
      "openjpeg                  2.4.0                hb211442_1    conda-forge\n",
      "openssl                   1.1.1l               h8ffe710_0    conda-forge\n",
      "packaging                 21.0               pyhd8ed1ab_0    conda-forge\n",
      "pandas                    1.3.3            py38h5d928e2_0    conda-forge\n",
      "pandoc                    2.14.2               h8ffe710_0    conda-forge\n",
      "pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\n",
      "parquet-cpp               1.5.1                         2    conda-forge\n",
      "parso                     0.8.2              pyhd3eb1b0_0  \n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
      "pillow                    8.3.2            py38h794f750_0    conda-forge\n",
      "pip                       21.2.2           py38haa95532_0  \n",
      "prometheus_client         0.11.0             pyhd8ed1ab_0    conda-forge\n",
      "prompt-toolkit            3.0.20             pyhd3eb1b0_0  \n",
      "pyarrow                   5.0.0           py38h9f6c39d_8_cpu    conda-forge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pycparser                 2.20               pyh9f0ad1d_2    conda-forge\n",
      "pygments                  2.10.0             pyhd3eb1b0_0  \n",
      "pyopenssl                 21.0.0             pyhd8ed1ab_0    conda-forge\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\n",
      "pyqt                      5.12.3           py38haa244fe_7    conda-forge\n",
      "pyqt-impl                 5.12.3           py38h885f38d_7    conda-forge\n",
      "pyqt5-sip                 4.19.18          py38h885f38d_7    conda-forge\n",
      "pyqtchart                 5.12             py38h885f38d_7    conda-forge\n",
      "pyqtwebengine             5.12.1           py38h885f38d_7    conda-forge\n",
      "pyrsistent                0.18.0                   pypi_0    pypi\n",
      "pysocks                   1.7.1            py38haa244fe_3    conda-forge\n",
      "python                    3.8.12               h6244533_0  \n",
      "python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge\n",
      "python-xxhash             2.0.2            py38h294d835_0    conda-forge\n",
      "python_abi                3.8                      1_cp38    huggingface\n",
      "pytorch                   1.9.1           py3.8_cuda11.1_cudnn8_0    pytorch\n",
      "pytz                      2021.3             pyhd8ed1ab_0    conda-forge\n",
      "pywin32                   228              py38hbaba5e8_1  \n",
      "pywinpty                  1.1.4                    pypi_0    pypi\n",
      "pyyaml                    6.0                      pypi_0    pypi\n",
      "pyzmq                     22.2.1           py38hd77b12b_1  \n",
      "qt                        5.12.9               h5909a2a_4    conda-forge\n",
      "re2                       2021.09.01           h0e60522_0    conda-forge\n",
      "regex                     2021.8.3         py38h2bbff1b_0  \n",
      "requests                  2.25.1             pyhd3deb0d_0    conda-forge\n",
      "s3transfer                0.5.0              pyhd3eb1b0_0  \n",
      "sacremoses                master                     py_0    huggingface\n",
      "scikit-learn              1.0              py38h8224a6f_1    conda-forge\n",
      "scipy                     1.7.1            py38ha1292f7_0    conda-forge\n",
      "send2trash                1.8.0              pyhd8ed1ab_0    conda-forge\n",
      "sentencepiece             0.1.96                   pypi_0    pypi\n",
      "setuptools                58.0.4           py38haa95532_0  \n",
      "six                       1.16.0             pyh6c4a22f_0    conda-forge\n",
      "snappy                    1.1.8                ha925a31_3    conda-forge\n",
      "sqlite                    3.36.0               h2bbff1b_0  \n",
      "tbb                       2021.3.0             h2d74725_0    conda-forge\n",
      "terminado                 0.12.1                   pypi_0    pypi\n",
      "testpath                  0.5.0              pyhd8ed1ab_0    conda-forge\n",
      "threadpoolctl             3.0.0              pyh8a188c0_0    conda-forge\n",
      "tk                        8.6.11               h8ffe710_1    conda-forge\n",
      "tokenizers                0.10.3           py38h291c280_1    conda-forge\n",
      "torchaudio                0.9.1                      py38    pytorch\n",
      "torchvision               0.2.2                      py_3    pytorch\n",
      "tornado                   6.1              py38h2bbff1b_0  \n",
      "tqdm                      4.62.3                   pypi_0    pypi\n",
      "traitlets                 5.1.0              pyhd3eb1b0_0  \n",
      "transformers              4.11.3             pyhd8ed1ab_0    conda-forge\n",
      "typing-extensions         3.10.0.2             hd8ed1ab_0    conda-forge\n",
      "typing_extensions         3.10.0.2           pyha770c72_0    conda-forge\n",
      "urllib3                   1.26.7             pyhd8ed1ab_0    conda-forge\n",
      "vc                        14.2                 h21ff451_1  \n",
      "vs2015_runtime            14.27.29016          h5e58377_2  \n",
      "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "wheel                     0.37.0             pyhd3eb1b0_1  \n",
      "widgetsnbextension        3.5.1            py38haa244fe_4    conda-forge\n",
      "win_inet_pton             1.1.0            py38haa244fe_2    conda-forge\n",
      "wincertstore              0.2              py38haa95532_2  \n",
      "winpty                    0.4.3                         4    conda-forge\n",
      "xxhash                    0.8.0                h8ffe710_3    conda-forge\n",
      "xz                        5.2.5                h62dcd97_1    conda-forge\n",
      "yaml                      0.2.5                he774522_0    conda-forge\n",
      "yarl                      1.7.0            py38h294d835_0    conda-forge\n",
      "zipp                      3.6.0              pyhd8ed1ab_0    conda-forge\n",
      "zlib                      1.2.11            h8ffe710_1013    conda-forge\n",
      "zstd                      1.5.0                h6255e5f_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa284b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3c74f98dfb436e92a1438e6b730486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba8935",
   "metadata": {},
   "source": [
    "# START\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a559a305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    TrainerCallback,\n",
    "    GPT2Config,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    AdamW,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from transformers import (GPT2Config,\n",
    "                          GPT2LMHeadModel)\n",
    "\n",
    "model_name = 'movie-plot-generation-from-scratch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d54c69",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "\n",
    "First, we load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c379c5e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2fcf8d2135508f85\n",
      "Reusing dataset text (C:\\Users\\Anton\\.cache\\huggingface\\datasets\\text\\default-2fcf8d2135508f85\\0.0.0\\e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63f938351cc4bb5adc8617b6d5d011e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 37031\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset from text file called \"data.txt\". We won't use a validation set\n",
    "dataset = load_dataset(\"text\", data_files=\"data_top_15_genres.txt\")['train']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bbb865",
   "metadata": {},
   "source": [
    "## Tokenizer training\n",
    "\n",
    "We now need to tokenize the dataset. We create a tokenizer and train it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b4830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('movie-plot-generation-from-scratch\\\\tokenizer_config.json',\n",
       " 'movie-plot-generation-from-scratch\\\\special_tokens_map.json',\n",
       " 'movie-plot-generation-from-scratch\\\\tokenizer.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add special tokens for each genre\n",
    "genres = ['romantic drama', 'short film', 'family film',\n",
    "          'adventure', 'action/adventure', 'indie',\n",
    "          'black-and-white', 'horror', 'crime fiction',\n",
    "          'world cinema', 'action', 'thriller', \n",
    "          'romance film', 'comedy', 'drama']\n",
    "\n",
    "special_tokens = ['<UNK>', '<BOS>', '<EOS>', '<PAD>', '<SEP>']\n",
    "genre_tokens =  [f'<{genre}>' for genre in genres]\n",
    "all_special_tokens = special_tokens + genre_tokens\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"<UNK>\"))\n",
    "trainer = BpeTrainer(special_tokens=all_special_tokens, vocab_size=50257)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.train_from_iterator(dataset['text'], trainer)\n",
    "\n",
    "# load our tokenizer into huggingface transformers library \n",
    "# For some reason the special tokens are not assigned to the corresponding properties \n",
    "# even though tokenization works as intended. We therefore add the special tokens manually.\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer, \n",
    "    model_input_names=['input_ids', 'attention_mask'])\n",
    "special_tokens_dict = {'additional_special_tokens': genre_tokens}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "tokenizer.unk_token = '<UNK>'\n",
    "tokenizer.bos_token = '<BOS>'\n",
    "tokenizer.eos_token = '<EOS>'\n",
    "tokenizer.pad_token = '<PAD>'\n",
    "tokenizer.sep_token = '<SEP>'\n",
    "\n",
    "# Save \n",
    "tokenizer.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9618f3d",
   "metadata": {},
   "source": [
    "### Define transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b61af20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='movie-plot-generation-from-scratch', vocab_size=50257, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'bos_token': '<BOS>', 'eos_token': '<EOS>', 'unk_token': '<UNK>', 'sep_token': '<SEP>', 'pad_token': '<PAD>', 'additional_special_tokens': ['<romantic drama>', '<short film>', '<family film>', '<adventure>', '<action/adventure>', '<indie>', '<black-and-white>', '<horror>', '<crime fiction>', '<world cinema>', '<action>', '<thriller>', '<romance film>', '<comedy>', '<drama>']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a new GPT2 model with 512 max length\n",
    "config = GPT2Config(\n",
    "    vocab_size=50257,\n",
    "    n_positions=512,\n",
    "    n_ctx=512,\n",
    ")\n",
    "model = GPT2LMHeadModel(config=config)\n",
    "\n",
    "# Load tokenizer \n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d6e30",
   "metadata": {},
   "source": [
    "**Tokenize the dataset**\n",
    "\n",
    "We tokenize the dataset. The tokenized examples contain the column names 'attention_mask' which is a mask for padding tokens and 'input_ids' which is the id of each token corrsponding to a word. We drop the text as that is not needed anymore. Also note that we duplicate the inputs to add our labels. This is because the model of the 🤗 Transformers library apply the shifting to the right, so we don't need to do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22681185",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8378a87d444142f0935c7527695f4264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=38.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'input_ids', 'labels'],\n",
       "    num_rows: 37031\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"], max_length=512, padding='max_length', truncation=True)\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "#Make dataset format pytorch tensors\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "# Finally, select a subset if wanted\n",
    "train_set = tokenized_dataset#.select(list(range(10)))\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fefa121",
   "metadata": {},
   "source": [
    "### Training\n",
    "First, setup training args.\n",
    "The last argument to setup everything so we can push the model to the Hub regularly during training..\n",
    "\n",
    "Then pass training args to Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6034ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveTokenizer(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A callback used to save the tokenizer whenever a model checkpoint is saved.\n",
    "    \"\"\"\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        tokenizer.save_pretrained(model_name)\n",
    "\n",
    "        \n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    The compute function needs to receive a tuple (with logits and labels)\n",
    "    and has to return a dictionary with string keys (the name of the metric) and float values.\n",
    "    It will be called at the end of each evaluation phase on the whole arrays of predictions/labels.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    # Calculate perplexity https://huggingface.co/transformers/perplexity.html\n",
    "    # \"the exponentiation of the cross-entropy between the data and model predictions.\"\n",
    "    \n",
    "    perplexity = math.exp(ce_loss(logits, labels))\n",
    "    \n",
    "    return {'perplexity': perplexity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce3eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "batch_size = 2 # 1:34:39 for one epoch (no evaluation steps) with batch_size = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    model_name,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=1,\n",
    "    log_level='info',\n",
    "    logging_steps=250\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[SaveTokenizer],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3df559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 37031\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='772' max='18516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  772/18516 02:58 < 1:08:43, 4.30 it/s, Epoch 0.04/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.548800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.712600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_results=trainer.train()\n",
    "pickle.dump(train_results, open(model_name+\"/train_results.pickle\", \"wb\")) #Load: train_results = pickle.load(open(\"train_results.pickle\", \"rb\"))\n",
    "\n",
    "model.save_pretrained(model_name)\n",
    "tokenizer.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89be0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference test\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "stories = generator(\"<BOS> <romantic drama> Expecting the unexpected <SEP> Kajsa and Anton are\", max_length=512, num_return_sequences=4)\n",
    "print(*[story['generated_text'] + \"\\n\\n\\n------------------------\\n\" for story in stories])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d7364",
   "metadata": {},
   "source": [
    "### Push to HUB\n",
    "\n",
    "Push tokenizer and model to hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094df378",
   "metadata": {},
   "source": [
    "### Casual language modeling ## \n",
    "For causal language modeling (CLM) we are going to take all the texts in our dataset and concatenate them after they are tokenized. Then we will split them in examples of a certain sequence length. This way the model will receive chunks of contiguous text that may look like:\n",
    "    \n",
    "    part of text 1\n",
    "    \n",
    "or\n",
    "\n",
    "    end of text 1 <BOS_TOKEN> beginning of text 2\n",
    "    \n",
    " \n",
    "depending on whether they span over several of the original texts in the dataset or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea116cb2",
   "metadata": {},
   "source": [
    "Now for the harder part: we need to concatenate all our texts together then split the result in small chunks of a certain block_size. To do this, we will use the map method again, with the option batched=True. This option actually lets us change the number of examples in the datasets by returning a different number of examples than we got. This way, we can create our new samples from a batch of examples.\n",
    "First, we grab the maximum length our model was pretrained with. This might be a big too big to fit in our GPU RAM, in that case decrease the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0410fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5821617",
   "metadata": {},
   "source": [
    "Then we write the preprocessing function that will group our texts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508479f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905bd446",
   "metadata": {},
   "source": [
    "First note that we duplicate the inputs for our labels. This is because the model of the 🤗 Transformers library apply the shifting to the right, so we don't need to do it manually.\n",
    "\n",
    "Also note that by default, the map method will send a batch of 1,000 examples to be treated by the preprocessing function. So here, we will drop the remainder to make the concatenated tokenized texts a multiple of block_size every 1,000 examples. You can adjust this behavior by passing a higher batch size (which will also be processed slower). You can also speed-up the preprocessing by using multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb277ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")\n",
    "print(lm_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60be398d",
   "metadata": {},
   "source": [
    "And we can check our datasets have changed: now the samples contain chunks of block_size contiguous tokens, potentially spanning over several of our original texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e003957",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(lm_datasets[\"train\"][0][\"input_ids\"]))\n",
    "print()\n",
    "print(tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399c21f",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned, we're ready to instantiate our Trainer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
